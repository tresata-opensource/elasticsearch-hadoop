diff --git a/build.gradle b/build.gradle
index 5fac802..7bc24b4 100644
--- a/build.gradle
+++ b/build.gradle
@@ -643,10 +643,10 @@ allprojects { project ->
         
         ignoreFailures = true
         
-        minHeapSize = "256m"
-        maxHeapSize = "768m"
+        minHeapSize = "1024m"
+        maxHeapSize = "4096m"
         if (!java8)
-            jvmArgs '-XX:MaxPermSize=496m'
+            jvmArgs '-XX:MaxPermSize=1024m'
 
         testLogging {
             displayGranularity 0
diff --git a/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java b/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java
index 7838457..f5de7e6 100644
--- a/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java
+++ b/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java
@@ -96,6 +96,18 @@ public class AbstractCascadingHadoopSearchTest {
     }
 
     @Test
+    public void testReadFromESWithoutFields() throws Exception {
+        Tap in = new EsTap("cascading-hadoop/artists", query);
+        Pipe pipe = new Pipe("copy");
+        pipe = new Each(pipe, AssertionLevel.STRICT, new AssertSizeEquals(3));
+        pipe = new Each(pipe, AssertionLevel.STRICT, new AssertNotNull());
+
+        // print out
+        Tap out = new HadoopPrintStreamTap(Stream.NULL);
+        build(cfg(), in, out, pipe);
+    }
+
+    @Test
     public void testReadFromESAliasedField() throws Exception {
         Tap in = new EsTap("cascading-hadoop/alias", query, new Fields("address"));
         Pipe pipe = new Pipe("copy");
diff --git a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java
index 73a30fd..c58c2a0 100644
--- a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java
+++ b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java
@@ -28,6 +28,8 @@ import org.elasticsearch.hadoop.serialization.builder.FilteringValueWriter;
 import org.elasticsearch.hadoop.serialization.builder.JdkValueWriter;
 
 import cascading.scheme.SinkCall;
+import cascading.tuple.Fields;
+import cascading.tuple.TupleEntry;
 import cascading.tuple.Tuple;
 
 /**
@@ -50,9 +52,25 @@ public class CascadingValueWriter extends FilteringValueWriter<SinkCall<Object[]
     @SuppressWarnings("unchecked")
     @Override
     public Result write(SinkCall<Object[], ?> sinkCall, Generator generator) {
-        Tuple tuple = CascadingUtils.coerceToString(sinkCall);
         // consider names (in case of aliases these are already applied)
         List<String> names = (List<String>) sinkCall.getContext()[0];
+        Object typesContext = null;
+        if (sinkCall.getContext().length > 1) typesContext = sinkCall.getContext()[1];
+
+        final TupleEntry entry = sinkCall.getOutgoingEntry();
+        final Fields fields = entry.getFields();
+        final Tuple tuple;
+
+        if (fields.hasTypes() || typesContext == null) {
+            tuple = CascadingUtils.coerceToString(sinkCall);
+        } else {
+            Class[] types = (Class[]) typesContext;
+            if (types.length == fields.size()) {
+                tuple = entry.getCoercedTuple(types);
+            } else {
+                tuple = CascadingUtils.coerceToString(sinkCall);
+            }
+        }
 
         generator.writeBeginObject();
         for (int i = 0; i < tuple.size(); i++) {
diff --git a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java
index 43282fd..619f09e 100644
--- a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java
+++ b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java
@@ -19,17 +19,24 @@
 package org.elasticsearch.hadoop.cascading;
 
 import java.io.IOException;
+import java.util.Collections;
 import java.util.Collection;
+import java.util.Iterator;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 
+import org.apache.commons.io.IOUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.mapred.JobConf;
 import org.apache.hadoop.mapred.OutputCollector;
 import org.apache.hadoop.mapred.RecordReader;
+import org.elasticsearch.hadoop.cfg.ConfigurationOptions;
+import org.elasticsearch.hadoop.cfg.HadoopSettings;
 import org.elasticsearch.hadoop.cfg.HadoopSettingsManager;
 import org.elasticsearch.hadoop.cfg.InternalConfigurationOptions;
 import org.elasticsearch.hadoop.cfg.Settings;
@@ -37,6 +44,7 @@ import org.elasticsearch.hadoop.mr.EsInputFormat;
 import org.elasticsearch.hadoop.mr.EsOutputFormat;
 import org.elasticsearch.hadoop.mr.HadoopCfgUtils;
 import org.elasticsearch.hadoop.rest.InitializationUtils;
+import org.elasticsearch.hadoop.rest.RestClient;
 import org.elasticsearch.hadoop.serialization.builder.JdkValueReader;
 import org.elasticsearch.hadoop.util.FieldAlias;
 import org.elasticsearch.hadoop.util.SettingsUtils;
@@ -51,6 +59,9 @@ import cascading.tuple.Fields;
 import cascading.tuple.Tuple;
 import cascading.tuple.TupleEntry;
 
+import org.codehaus.jackson.JsonNode;
+import org.codehaus.jackson.map.ObjectMapper;
+
 /**
  * Cascading Scheme handling
  */
@@ -64,6 +75,18 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
     private final String nodes;
     private final int port;
     private final Properties props;
+    private Class[] types = new Class[0];
+    private static final Map<String, Class> typesMap;
+    static {
+        Map<String, Class> m = new java.util.HashMap<String, Class>();
+        m.put("string", String.class);
+        m.put("integer", int.class);
+        m.put("long", long.class);
+        m.put("float", float.class);
+        m.put("double", double.class);
+        m.put("boolean", boolean.class);
+        typesMap = Collections.unmodifiableMap(m);
+    }
     private boolean IS_ES_20;
 
     private static Log log = LogFactory.getLog(EsHadoopScheme.class);
@@ -105,10 +128,11 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
     public void sinkPrepare(FlowProcess<JobConf> flowProcess, SinkCall<Object[], OutputCollector> sinkCall) throws IOException {
         super.sinkPrepare(flowProcess, sinkCall);
 
-        Object[] context = new Object[1];
+        Object[] context = new Object[2];
         // the tuple is fixed, so we can just use a collection/index
         Settings settings = loadSettings(flowProcess.getConfigCopy(), false);
         context[0] = CascadingUtils.fieldToAlias(settings, getSinkFields());
+        context[1] = types;
         sinkCall.setContext(context);
         IS_ES_20 = SettingsUtils.isEs20(settings);
     }
@@ -120,6 +144,46 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
     }
 
     @Override
+    public Fields retrieveSourceFields(final FlowProcess<JobConf> flowProcess, final Tap tap) {
+        Settings settings = loadSettings(flowProcess.getConfigCopy(), false);
+        if (getSourceFields() == Fields.UNKNOWN && settings.getFieldDetection()) {
+            log.info("resource: " + index);
+            String[] parts = index.split("/");
+            if (parts.length == 2) {
+                String myIndex = parts[0];
+                String docType = parts[1];
+                log.info("index: " + myIndex + ", type: " + docType);
+
+                String mappingsUrl = "/" + myIndex + "/_mapping/" + docType;
+                log.info("mapping URL: " + mappingsUrl);
+                RestClient client = new RestClient(settings);
+                try {
+                    String responseBody = IOUtils.toString(client.getRaw(mappingsUrl));
+
+                    // extract fields from the response body
+                    JsonNode mappingsObj = new ObjectMapper().readTree(responseBody)
+                        .path(myIndex).path("mappings")
+                        .path(docType).path("properties");
+                    Iterator<String> fieldsIterator = mappingsObj.getFieldNames();
+                    List<String> fieldList = new ArrayList<String>();
+                    while (fieldsIterator.hasNext())
+                        fieldList.add(fieldsIterator.next());
+                    String[] fieldNames = new String[fieldList.size()];
+                    fieldList.toArray(fieldNames);
+                    Fields fields = new Fields(fieldNames);
+                    log.info("fields: " + fieldNames);
+                    setSourceFields(fields);
+                } catch (IOException e) {
+                    log.info("no fields found in the mapping");
+                } finally {
+                    client.close();
+                }
+            }
+        }
+        return getSourceFields();
+    }
+
+    @Override
     public void sourceConfInit(FlowProcess<JobConf> flowProcess, Tap<JobConf, RecordReader, OutputCollector> tap, JobConf conf) {
         conf.setInputFormat(EsInputFormat.class);
         Settings set = loadSettings(conf, true);
@@ -154,6 +218,75 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
         if (log.isTraceEnabled()) {
             log.trace("Initialized (sink) configuration " + HadoopCfgUtils.asProperties(conf));
         }
+
+        String[] parts = index.split("/");
+
+        // set the es_mapping_id if the _id : path value is set for the index/type
+        if (parts.length == 2) {
+            String currentId = conf.get(ConfigurationOptions.ES_MAPPING_ID);
+            if (currentId == null) {
+                String myIndex = parts[0];
+                String docType = parts[1];
+                String indexUrl = "/" + myIndex;
+                log.info("index URL: " + indexUrl);
+                Settings settings = new HadoopSettings(conf);
+                RestClient client = new RestClient(settings);
+                try {
+                    java.io.InputStream response = client.getRaw(indexUrl);
+                    String responseBody = IOUtils.toString(response);
+
+                    // extract _id path
+                    JsonNode mappingsObj = new ObjectMapper().readTree(responseBody)
+                        .path(myIndex).path("mappings")
+                        .path(docType).path("_id").path("path");
+                    String idField = mappingsObj.getTextValue();
+                    conf.set(ConfigurationOptions.ES_MAPPING_ID, idField);
+                } catch (Exception e) {
+                    // If there is no stored _id, just continue without setting it
+                    log.info("No es.mapping.id specified");
+                } finally {
+                    client.close();
+                }
+            }
+        }
+
+        // grab any types stored in the index/type properties, in order to apply casts on the tuples
+        if (parts.length == 2 && set.getTypeDetection()) {
+            String myIndex = parts[0];
+            String docType = parts[1];
+            String mappingsUrl = "/" + myIndex + "/_mappings";
+            log.info("mappings URL: " + mappingsUrl);
+            Settings settings = new HadoopSettings(conf);
+            RestClient client = new RestClient(settings);
+            try {
+                java.io.InputStream response = client.getRaw(mappingsUrl);
+                String responseBody = IOUtils.toString(response);
+
+                // extract map of fields to classes
+                JsonNode mappingsObj = new ObjectMapper().readTree(responseBody)
+                    .path(myIndex).path("mappings")
+                    .path(docType).path("properties");
+                Iterator<java.util.Map.Entry<String, JsonNode>> nodeIterator = mappingsObj.getFields();
+                Map<String, Class> classMap = new java.util.HashMap<String, Class>();
+                while (nodeIterator.hasNext()) {
+                    java.util.Map.Entry<String, JsonNode> entry = nodeIterator.next();
+                    classMap.put(entry.getKey(), typesMap.get(entry.getValue().findValue("type").getTextValue()));
+                }
+
+                // create array of types corresponding to the sink fields
+                Fields fields = getSinkFields();
+                types = new Class[fields.size()];
+                for (int i = 0; i < fields.size(); i++) {
+                    types[i] = classMap.get(fields.get(i));
+                }
+
+            } catch (Exception e) {
+                // if there are no mappings stored, continue as usual
+                log.info("No field types found");
+            } finally {
+                client.close();
+            }
+        }
     }
 
     private Settings loadSettings(Object source, boolean read) {
@@ -204,4 +337,4 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
     public void sink(FlowProcess<JobConf> flowProcess, SinkCall<Object[], OutputCollector> sinkCall) throws IOException {
         sinkCall.getOutput().collect(null, sinkCall);
     }
-}
\ No newline at end of file
+}
diff --git a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java
index 0c47955..cafd37e 100644
--- a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java
+++ b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java
@@ -141,6 +141,12 @@ public class EsTap extends Tap<Object, Object, Object> {
     }
 
     @Override
+    public Fields retrieveSourceFields(FlowProcess<Object> flowProcess) {
+        initInnerTapIfNotSetFromFlowProcess(flowProcess);
+        return actualTap.retrieveSourceFields(flowProcess);
+    }
+
+    @Override
     public TupleEntryCollector openForWrite(FlowProcess<Object> flowProcess, Object output) throws IOException {
         initInnerTapIfNotSetFromFlowProcess(flowProcess);
         return actualTap.openForWrite(flowProcess, output);
diff --git a/diff.txt b/diff.txt
new file mode 100644
index 0000000..f5255af
--- /dev/null
+++ b/diff.txt
@@ -0,0 +1,369 @@
+diff --git a/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java b/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java
+index bdc53c9..f8262c3 100644
+--- a/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java
++++ b/cascading/src/itest/java/org/elasticsearch/hadoop/integration/cascading/AbstractCascadingHadoopSearchTest.java
+@@ -96,6 +96,18 @@ public class AbstractCascadingHadoopSearchTest {
+     }
+ 
+     @Test
++    public void testReadFromESWithoutFields() throws Exception {
++        Tap in = new EsTap("cascading-hadoop/artists", query);
++        Pipe pipe = new Pipe("copy");
++        pipe = new Each(pipe, AssertionLevel.STRICT, new AssertSizeEquals(3));
++        pipe = new Each(pipe, AssertionLevel.STRICT, new AssertNotNull());
++
++        // print out
++        Tap out = new HadoopPrintStreamTap(Stream.NULL);
++        build(cfg(), in, out, pipe);
++    }
++
++    @Test
+     public void testReadFromESAliasedField() throws Exception {
+         Tap in = new EsTap("cascading-hadoop/alias", query, new Fields("address"));
+         Pipe pipe = new Pipe("copy");
+diff --git a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java
+index 73a30fd..c58c2a0 100644
+--- a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java
++++ b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/CascadingValueWriter.java
+@@ -28,6 +28,8 @@ import org.elasticsearch.hadoop.serialization.builder.FilteringValueWriter;
+ import org.elasticsearch.hadoop.serialization.builder.JdkValueWriter;
+ 
+ import cascading.scheme.SinkCall;
++import cascading.tuple.Fields;
++import cascading.tuple.TupleEntry;
+ import cascading.tuple.Tuple;
+ 
+ /**
+@@ -50,9 +52,25 @@ public class CascadingValueWriter extends FilteringValueWriter<SinkCall<Object[]
+     @SuppressWarnings("unchecked")
+     @Override
+     public Result write(SinkCall<Object[], ?> sinkCall, Generator generator) {
+-        Tuple tuple = CascadingUtils.coerceToString(sinkCall);
+         // consider names (in case of aliases these are already applied)
+         List<String> names = (List<String>) sinkCall.getContext()[0];
++        Object typesContext = null;
++        if (sinkCall.getContext().length > 1) typesContext = sinkCall.getContext()[1];
++
++        final TupleEntry entry = sinkCall.getOutgoingEntry();
++        final Fields fields = entry.getFields();
++        final Tuple tuple;
++
++        if (fields.hasTypes() || typesContext == null) {
++            tuple = CascadingUtils.coerceToString(sinkCall);
++        } else {
++            Class[] types = (Class[]) typesContext;
++            if (types.length == fields.size()) {
++                tuple = entry.getCoercedTuple(types);
++            } else {
++                tuple = CascadingUtils.coerceToString(sinkCall);
++            }
++        }
+ 
+         generator.writeBeginObject();
+         for (int i = 0; i < tuple.size(); i++) {
+diff --git a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java
+index ba4798f..09646a1 100644
+--- a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java
++++ b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsHadoopScheme.java
+@@ -19,24 +19,32 @@
+ package org.elasticsearch.hadoop.cascading;
+ 
+ import java.io.IOException;
++import java.util.Collections;
+ import java.util.Collection;
++import java.util.Iterator;
++import java.util.ArrayList;
+ import java.util.List;
+ import java.util.Map;
+ import java.util.Properties;
+ 
++import org.apache.commons.io.IOUtils;
+ import org.apache.commons.logging.Log;
+ import org.apache.commons.logging.LogFactory;
++import org.apache.hadoop.conf.Configuration;
+ import org.apache.hadoop.io.Text;
+ import org.apache.hadoop.mapred.JobConf;
+ import org.apache.hadoop.mapred.OutputCollector;
+ import org.apache.hadoop.mapred.RecordReader;
++import org.elasticsearch.hadoop.cfg.ConfigurationOptions;
+ import org.elasticsearch.hadoop.cfg.InternalConfigurationOptions;
+ import org.elasticsearch.hadoop.cfg.Settings;
++import org.elasticsearch.hadoop.cfg.HadoopSettings;
+ import org.elasticsearch.hadoop.cfg.HadoopSettingsManager;
+ import org.elasticsearch.hadoop.mr.EsInputFormat;
+ import org.elasticsearch.hadoop.mr.EsOutputFormat;
+ import org.elasticsearch.hadoop.mr.HadoopCfgUtils;
+ import org.elasticsearch.hadoop.rest.InitializationUtils;
++import org.elasticsearch.hadoop.rest.RestClient;
+ import org.elasticsearch.hadoop.serialization.builder.JdkValueReader;
+ import org.elasticsearch.hadoop.util.FieldAlias;
+ import org.elasticsearch.hadoop.util.SettingsUtils;
+@@ -51,6 +59,9 @@ import cascading.tuple.Fields;
+ import cascading.tuple.Tuple;
+ import cascading.tuple.TupleEntry;
+ 
++import org.codehaus.jackson.JsonNode;
++import org.codehaus.jackson.map.ObjectMapper;
++
+ /**
+  * Cascading Scheme handling
+  */
+@@ -64,7 +75,19 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
+     private final String nodes;
+     private final int port;
+     private final Properties props;
++    private Class[] types = new Class[0];
+     private boolean IS_ES_10;
++    private static final Map<String, Class> typesMap;
++    static {
++        Map<String, Class> m = new java.util.HashMap<String, Class>();
++        m.put("string", String.class);
++        m.put("integer", int.class);
++        m.put("long", long.class);
++        m.put("float", float.class);
++        m.put("double", double.class);
++        m.put("boolean", boolean.class);
++        typesMap = Collections.unmodifiableMap(m);
++    }
+ 
+     private static Log log = LogFactory.getLog(EsHadoopScheme.class);
+ 
+@@ -105,10 +128,11 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
+     public void sinkPrepare(FlowProcess<JobConf> flowProcess, SinkCall<Object[], OutputCollector> sinkCall) throws IOException {
+         super.sinkPrepare(flowProcess, sinkCall);
+ 
+-        Object[] context = new Object[1];
++        Object[] context = new Object[2];
+         // the tuple is fixed, so we can just use a collection/index
+         Settings settings = loadSettings(flowProcess.getConfigCopy(), false);
+         context[0] = CascadingUtils.fieldToAlias(settings, getSinkFields());
++        context[1] = types;
+         sinkCall.setContext(context);
+         IS_ES_10 = SettingsUtils.isEs10(settings);
+     }
+@@ -120,6 +144,46 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
+     }
+ 
+     @Override
++    public Fields retrieveSourceFields(final FlowProcess<JobConf> flowProcess, final Tap tap) {
++        Settings settings = loadSettings(flowProcess.getConfigCopy(), false);
++        if (getSourceFields() == Fields.UNKNOWN && settings.getFieldDetection()) {
++            log.info("resource: " + index);
++            String[] parts = index.split("/");
++            if (parts.length == 2) {
++                String myIndex = parts[0];
++                String docType = parts[1];
++                log.info("index: " + myIndex + ", type: " + docType);
++
++                String mappingsUrl = "/" + myIndex + "/_mapping/" + docType;
++                log.info("mapping URL: " + mappingsUrl);
++                RestClient client = new RestClient(settings);
++                try {
++                    String responseBody = IOUtils.toString(client.getRaw(mappingsUrl));
++
++                    // extract fields from the response body
++                    JsonNode mappingsObj = new ObjectMapper().readTree(responseBody)
++                        .path(myIndex).path("mappings")
++                        .path(docType).path("properties");
++                    Iterator<String> fieldsIterator = mappingsObj.getFieldNames();
++                    List<String> fieldList = new ArrayList<String>();
++                    while (fieldsIterator.hasNext())
++                        fieldList.add(fieldsIterator.next());
++                    String[] fieldNames = new String[fieldList.size()];
++                    fieldList.toArray(fieldNames);
++                    Fields fields = new Fields(fieldNames);
++                    log.info("fields: " + fieldNames);
++                    setSourceFields(fields);
++                } catch (IOException e) {
++                    log.info("no fields found in the mapping");
++                } finally {
++                    client.close();
++                }
++            }
++        }
++        return getSourceFields();
++    }
++
++    @Override
+     public void sourceConfInit(FlowProcess<JobConf> flowProcess, Tap<JobConf, RecordReader, OutputCollector> tap, JobConf conf) {
+         conf.setInputFormat(EsInputFormat.class);
+         Settings set = loadSettings(conf, true);
+@@ -154,6 +218,75 @@ class EsHadoopScheme extends Scheme<JobConf, RecordReader, OutputCollector, Obje
+         if (log.isTraceEnabled()) {
+             log.trace("Initialized (sink) configuration " + HadoopCfgUtils.asProperties(conf));
+         }
++
++        String[] parts = index.split("/");
++
++        // set the es_mapping_id if the _id : path value is set for the index/type
++        if (parts.length == 2) {
++            String currentId = conf.get(ConfigurationOptions.ES_MAPPING_ID);
++            if (currentId == null) {
++                String myIndex = parts[0];
++                String docType = parts[1];
++                String indexUrl = "/" + myIndex;
++                log.info("index URL: " + indexUrl);
++                Settings settings = new HadoopSettings(conf);
++                RestClient client = new RestClient(settings);
++                try {
++                    java.io.InputStream response = client.getRaw(indexUrl);
++                    String responseBody = IOUtils.toString(response);
++
++                    // extract _id path
++                    JsonNode mappingsObj = new ObjectMapper().readTree(responseBody)
++                        .path(myIndex).path("mappings")
++                        .path(docType).path("_id").path("path");
++                    String idField = mappingsObj.getTextValue();
++                    conf.set(ConfigurationOptions.ES_MAPPING_ID, idField);
++                } catch (Exception e) {
++                    // If there is no stored _id, just continue without setting it
++                    log.info("No es.mapping.id specified");
++                } finally {
++                    client.close();
++                }
++            }
++        }
++
++        // grab any types stored in the index/type properties, in order to apply casts on the tuples
++        if (parts.length == 2 && set.getTypeDetection()) {
++            String myIndex = parts[0];
++            String docType = parts[1];
++            String mappingsUrl = "/" + myIndex + "/_mappings";
++            log.info("mappings URL: " + mappingsUrl);
++            Settings settings = new HadoopSettings(conf);
++            RestClient client = new RestClient(settings);
++            try {
++                java.io.InputStream response = client.getRaw(mappingsUrl);
++                String responseBody = IOUtils.toString(response);
++
++                // extract map of fields to classes
++                JsonNode mappingsObj = new ObjectMapper().readTree(responseBody)
++                    .path(myIndex).path("mappings")
++                    .path(docType).path("properties");
++                Iterator<java.util.Map.Entry<String, JsonNode>> nodeIterator = mappingsObj.getFields();
++                Map<String, Class> classMap = new java.util.HashMap<String, Class>();
++                while (nodeIterator.hasNext()) {
++                    java.util.Map.Entry<String, JsonNode> entry = nodeIterator.next();
++                    classMap.put(entry.getKey(), typesMap.get(entry.getValue().findValue("type").getTextValue()));
++                }
++
++                // create array of types corresponding to the sink fields
++                Fields fields = getSinkFields();
++                types = new Class[fields.size()];
++                for (int i = 0; i < fields.size(); i++) {
++                    types[i] = classMap.get(fields.get(i));
++                }
++
++            } catch (Exception e) {
++                // if there are no mappings stored, continue as usual
++                log.info("No field types found");
++            } finally {
++                client.close();
++            }
++        }
+     }
+ 
+     private Settings loadSettings(Object source, boolean read) {
+diff --git a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java
+index 0c47955..cafd37e 100644
+--- a/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java
++++ b/cascading/src/main/java/org/elasticsearch/hadoop/cascading/EsTap.java
+@@ -141,6 +141,12 @@ public class EsTap extends Tap<Object, Object, Object> {
+     }
+ 
+     @Override
++    public Fields retrieveSourceFields(FlowProcess<Object> flowProcess) {
++        initInnerTapIfNotSetFromFlowProcess(flowProcess);
++        return actualTap.retrieveSourceFields(flowProcess);
++    }
++
++    @Override
+     public TupleEntryCollector openForWrite(FlowProcess<Object> flowProcess, Object output) throws IOException {
+         initInnerTapIfNotSetFromFlowProcess(flowProcess);
+         return actualTap.openForWrite(flowProcess, output);
+diff --git a/dist.gradle b/dist.gradle
+index 554930a..340d7cc 100644
+--- a/dist.gradle
++++ b/dist.gradle
+@@ -87,11 +87,11 @@ uploadArchives {
+ 		mavenDeployer {
+ 			customizePom(pom, project)
+ 			
+-			repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
+-				authentication(userName: deployUsername(), password: deployPassword())
++			repository(url: "http://server01:8080/archiva/repository/internal/") {
++				authentication(userName: mavenUser, password: mavenPassword)
+             }
+-			snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
+-				authentication(userName: deployUsername(), password: deployPassword())
++			snapshotRepository(url: "http://server01:8080/archiva/repository/snapshots/") {
++				authentication(userName: mavenUser, password: mavenPassword)
+ 			}
+ 		}
+ 	}
+@@ -158,4 +158,4 @@ def uploadArtifactsToS3(target, toDir) {
+ 		  }
+ 		}
+ 	}
+-}
+\ No newline at end of file
++}
+diff --git a/gradle.properties b/gradle.properties
+index 875234e..f47d61a 100644
+--- a/gradle.properties
++++ b/gradle.properties
+@@ -43,4 +43,4 @@ groovyVersion = 2.3.2
+ # --------------------
+ # Project wide version
+ # --------------------
+-version=2.1.0.BUILD-SNAPSHOT
++version=2.1.0-tres1-SNAPSHOT
+diff --git a/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java b/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java
+index afd0be4..c09dff4 100644
+--- a/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java
++++ b/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java
+@@ -121,6 +121,10 @@ public interface ConfigurationOptions {
+     /** Field options **/
+     String ES_FIELD_READ_EMPTY_AS_NULL = "es.field.read.empty.as.null";
+     String ES_FIELD_READ_EMPTY_AS_NULL_DEFAULT = "yes";
++    String ES_AUTO_DETECT_FIELDS = "es.field.auto.detect";
++    String ES_AUTO_DETECT_FIELDS_DEFAULT = "false";
++    String ES_AUTO_CONVERT_TYPES = "es.field.detect.types";
++    String ES_AUTO_CONVERT_TYPES_DEFAULT = "false";
+ 
+     String ES_FIELD_READ_VALIDATE_PRESENCE = "es.field.read.validate.presence";
+     String ES_FIELD_READ_VALIDATE_PRESENCE_DEFAULT = "warn";
+diff --git a/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java b/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java
+index 1f5e8f0..69d962c 100644
+--- a/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java
++++ b/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java
+@@ -142,6 +142,14 @@ public abstract class Settings {
+         return Booleans.parseBoolean(getProperty(ES_OUTPUT_JSON, ES_OUTPUT_JSON_DEFAULT));
+     }
+ 
++    public boolean getFieldDetection() {
++        return Booleans.parseBoolean(getProperty(ES_AUTO_DETECT_FIELDS, ES_AUTO_DETECT_FIELDS_DEFAULT));
++    }
++
++    public boolean getTypeDetection() {
++        return Booleans.parseBoolean(getProperty(ES_AUTO_CONVERT_TYPES, ES_AUTO_CONVERT_TYPES_DEFAULT));
++    }
++
+     public String getOperation() {
+         return getProperty(ES_WRITE_OPERATION, ES_WRITE_OPERATION_DEFAULT).toLowerCase(Locale.ENGLISH);
+     }
+diff --git a/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java b/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java
+index d51dfdb..5cc98cb 100644
+--- a/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java
++++ b/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java
+@@ -118,6 +118,10 @@ public class RestClient implements Closeable, StatsAware {
+         return parseContent(execute(GET, q), string);
+     }
+ 
++    public InputStream getRaw(String q) {
++        return execute(GET, q);
++    }
++
+     @SuppressWarnings("unchecked")
+     private <T> T parseContent(InputStream content, String string) {
+         Map<String, Object> map = Collections.emptyMap();
diff --git a/dist.gradle b/dist.gradle
index d3506fa..828cb34 100644
--- a/dist.gradle
+++ b/dist.gradle
@@ -82,19 +82,19 @@ repositories {
 }
 
 uploadArchives {
-    repositories {
-        //add project.repositories.fileRepo
-        mavenDeployer {
-            customizePom(pom, project)
-            
-            repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
-                authentication(userName: deployUsername(), password: deployPassword())
-            }
-            snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
-                authentication(userName: deployUsername(), password: deployPassword())
+	repositories {
+		//add project.repositories.fileRepo
+		mavenDeployer {
+			customizePom(pom, project)
+			
+			repository(url: "http://server02:8080/repository/internal/") {
+				authentication(userName: mavenUser, password: mavenPassword)
             }
-        }
-    }
+			snapshotRepository(url: "http://server02:8080/repository/snapshots/") {
+				authentication(userName: mavenUser, password: mavenPassword)
+			}
+		}
+	}
 }
 
 install {
@@ -158,4 +158,4 @@ def uploadArtifactsToS3(target, toDir) {
           }
         }
     }
-}
\ No newline at end of file
+}
diff --git a/gradle.properties b/gradle.properties
index c53683e..c2a2c86 100644
--- a/gradle.properties
+++ b/gradle.properties
@@ -45,4 +45,4 @@ groovyVersion = 2.4.4
 # --------------------
 # Project wide version
 # --------------------
-version=2.2.0-rc1
+version=2.2.0-tres-rc1
diff --git a/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java b/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java
index 9417cb7..e45981a 100644
--- a/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java
+++ b/mr/src/main/java/org/elasticsearch/hadoop/cfg/ConfigurationOptions.java
@@ -135,6 +135,10 @@ public interface ConfigurationOptions {
     /** Field options **/
     String ES_FIELD_READ_EMPTY_AS_NULL = "es.field.read.empty.as.null";
     String ES_FIELD_READ_EMPTY_AS_NULL_DEFAULT = "yes";
+    String ES_AUTO_DETECT_FIELDS = "es.field.auto.detect";
+    String ES_AUTO_DETECT_FIELDS_DEFAULT = "false";
+    String ES_AUTO_CONVERT_TYPES = "es.field.detect.types";
+    String ES_AUTO_CONVERT_TYPES_DEFAULT = "false";
 
     String ES_FIELD_READ_VALIDATE_PRESENCE = "es.field.read.validate.presence";
     String ES_FIELD_READ_VALIDATE_PRESENCE_DEFAULT = "warn";
diff --git a/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java b/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java
index 9a244b8..98b5232 100644
--- a/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java
+++ b/mr/src/main/java/org/elasticsearch/hadoop/cfg/Settings.java
@@ -158,6 +158,14 @@ public abstract class Settings {
         return Booleans.parseBoolean(getProperty(ES_OUTPUT_JSON, ES_OUTPUT_JSON_DEFAULT));
     }
 
+    public boolean getFieldDetection() {
+        return Booleans.parseBoolean(getProperty(ES_AUTO_DETECT_FIELDS, ES_AUTO_DETECT_FIELDS_DEFAULT));
+    }
+
+    public boolean getTypeDetection() {
+        return Booleans.parseBoolean(getProperty(ES_AUTO_CONVERT_TYPES, ES_AUTO_CONVERT_TYPES_DEFAULT));
+    }
+
     public String getOperation() {
         return getProperty(ES_WRITE_OPERATION, ES_WRITE_OPERATION_DEFAULT).toLowerCase(Locale.ROOT);
     }
diff --git a/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java b/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java
index e463a5a..838e676 100644
--- a/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java
+++ b/mr/src/main/java/org/elasticsearch/hadoop/rest/RestClient.java
@@ -121,6 +121,10 @@ public class RestClient implements Closeable, StatsAware {
         return parseContent(execute(GET, q), string);
     }
 
+    public InputStream getRaw(String q) {
+        return execute(GET, q);
+    }
+
     @SuppressWarnings("unchecked")
     private <T> T parseContent(InputStream content, String string) {
         Map<String, Object> map = Collections.emptyMap();
